
#include <iostream>
#include <map>
#include <set>
#include <string>
#include <utility>
#include <vector>
#include <cmath>
#include <algorithm>


using namespace std;


const int MAX_RESULT_DOCUMENT_COUNT = 5;

// СЧИТЫВАЕТ ВВОД В ПОИСКУОВУЮ СТРОКУ
string ReadLine() {
	string s;
	getline(cin, s);
	return s;
}

// СЧИТАТЬ КОЛИЧЕСТВО ОЦЕНОК РЕЙТИНГА
vector<int> ReadLineNumberRatings() {
	int result;
	vector<int> ratings;
	cin >> result;
	for (int i = 0; i < result; ++i) {
		int r;
		cin >> r;
		ratings.push_back(r);
		r = 0;
	}
	ReadLine();
	return ratings;
}

// СЧИТЫВАЕТ ВВОД КОЛИЧЕСТВА ДОКУМЕНТОВ
int ReadLineWithNumber() { //Прочитать строку с номером
	int result;
	cin >> result;
	ReadLine();
	return result;
}



// ПЕРОБРАЗУЕТ СТРОКУ В ВЕКТОР
vector<string> SplitIntoWords(const string& text) { //Разделить на слова
	vector<string> words;
	string word;
	for (const char c : text) {
		if (c == ' ') {
			words.push_back(word);
			word = "";
		}
		else {
			word += c;
		}
	}
	words.push_back(word);

	return words;
}

// СТРУКТУРА ТРИАДЫ: id, релевантность, рейтинг
struct Document {
	int id;
	double relevance;
	int rating;
};

// КЛАСС
class SearchServer {
	// ПУБЛИЧНАЯ ЧАСТЬ
public:

	// УСТАНАВЛИВАЕТ СТОП-СЛОВА В ПОЛЕ stop_words_
	void SetStopWords(const string& text) {
		for (const string& word : SplitIntoWords(text)) {
			stop_words_.insert(word);
		}
	}

	// БАЗА ДАННЫХ ДОКУМЕНТОВ
	void AddDocument(int document_id, const string& document) {
		/* заносим документ в "количество документов" */
		++document_count_;

		/* Разбиваем строку документа на вектор строк из отдельных слов,
		чтобы для каждого из них заранее высчитать TF*/
		const vector<string> words = SplitIntoWordsNoStop(document);
		/* вычисляем TF каждого входящего слова */
		const double inv_word_count = 1.0 / words.size();
		for (const string& word : words) {
			word_to_document_freqs_[word][document_id] += inv_word_count;
		}

	}

	void AverageRating(int document_id, vector<int> ratings) {
		/* Вводим оценки и вычисляем средний рейтинг*/
		int average_rating = ComputeAverageRating(ratings);
		//вычислите средний рейтинг оценок и сохраняем в поле document_ratings_
		document_ratings_.insert({ document_id, average_rating });
	}

	//НАХОДИТ ПОПУЛЯРНЫЕ ДОКУМЕНТЫ
	vector<Document> FindTopDocuments(const string& raw_query) const {
		const Query query = ParseQuery(raw_query);
		vector<Document> matched_documents = FindAllDocuments(query);

		sort(matched_documents.begin(), matched_documents.end(),
			[](const Document& lhs, const Document& rhs) {
				return lhs.relevance > rhs.relevance;
			});
		if (matched_documents.size() > MAX_RESULT_DOCUMENT_COUNT) {
			matched_documents.resize(MAX_RESULT_DOCUMENT_COUNT);
		}
		return matched_documents;
	}

private:

	// ПОЛЕ: БИБЛИОТЕКА, ХРАНЯЩАЯ СЛОВА ДОКУМЕНТОВ, ID И TF К КАЖДОМУ ИЗ НИХ
	map<string, map<int, double>> word_to_document_freqs_; // слово для документирования частот

	// ПОЛЕ: МНОЖЕСТВО СТОП СЛОВ
	set<string> stop_words_;

	// ПОЛЕ: КОЛ-ВО ДОКУМЕНТОВ
	int document_count_ = 0;

	// ПОЛЕ: РЕЙТИНГ ДОКУМЕНТА
	map<int, int> document_ratings_; // {id документа, рейтинг}


	// МЕТОДЫ:

	// ОПРЕДЕЛЯЕТ - ЯВЛЯЕТСЯ ЛИ word СТОП-СЛОВОМ
	bool IsStopWord(const string& word) const {
		return stop_words_.count(word) > 0;
	}

	/*СТРУКТУРА ИЗ 3-х ПЕРЕМЕННЫХ :
	строки(слова) и булевых переменных (вероятных минус - и стоп - значений слова)*/
	struct QueryWord {
		string data;
		bool is_minus;
		bool is_stop;
	};

	/* РАЗБИВАЕТ, ОЧИШЕННУЮ ОТ СТОП-СЛОВ
	ВВЕДЕННУЮ СТРОКУ НА ВЕКТОР СЛОВ(string) */
	vector<string> SplitIntoWordsNoStop(const string& text) const {
		vector<string> words;
		for (const string& word : SplitIntoWords(text)) {
			if (!IsStopWord(word)) {
				words.push_back(word);
			}
		}
		return words;
	}

	/*ОПРЕДЕЛЯЕТ, ЯВЛЯЕТСЯ ЛИ СЛОВО МИНУС-СЛОВОМ.
	ЕСЛИ ЯВЛЯЕТСЯ, ТО ОПРЕДЕЛЯЕТ, ЯВЛЯЕТСЯ ЛИ ОНО СТОП-СЛОВОМ*/
	QueryWord ParseQueryWord(string text) const {
		bool is_minus = false;
		// Слово не должно быть пустым.
		if (text[0] == '-') {
			is_minus = true;
			text = text.substr(1);
		}
		return {
			text,
			is_minus,
			IsStopWord(text)
		};
	}

	//СТРУКТУРА ПАРЫ ИЗ 2-х ВЕКТОРОВ (плюс-слов и минус-слов)
	struct Query {
		vector<string> plus_words;
		vector<string> minus_words;
	};

	// ОПРЕДЕЛЯЕТ И СОХРАНЯЕТ ПЛЮС- И МИНУС- СЛОВА В 2 РАЗНЫХ ВЕКТОРА
	Query ParseQuery(const string& text) const {
		/*Объявляем переменную по стуктуре из
		пары векторов plus_words и minus_words*/
		Query query;
		for (const string& word : SplitIntoWords(text)) {
			/*Объявляем переменую по стуктуре из трех значений
			и сохраняем в неё резульат определения -
			является ли данное слово стоп- или минус- */
			const QueryWord query_word = ParseQueryWord(word);
			if (!query_word.is_stop) {
				if (query_word.is_minus) {
					query.minus_words.push_back(query_word.data);
				}
				else {
					query.plus_words.push_back(query_word.data);
				}
			}
		}
		return query;
	}

	/*Заготоавливаем функцию для вычисления IDF*/
	double IDF(const string& word) const {
		return log(document_count_ * 1.0 / word_to_document_freqs_.at(word).size());
	}

	// ВЫЧИСЛЯЕТ СРЕДНИЙ РЕЙТИНГ ДОКУМЕНТА
	int ComputeAverageRating(const vector<int>& ratings) const {
		int number_of_ratings = ratings.size();
		int sum = 0;
		if (ratings.size() > 0) {

			for (int i : ratings) {
				sum += i;
			}
			return sum / number_of_ratings;
		}
		else {
			return 0;
		}
	}

	/* ПРИНИМАЕТ ПАРУ ИЗ ВЕКТОРОВ (плюс- и минус- слов) поисковго запроса
	и возвращает вектором триад их id и вычесленную общую релевантность (TF-IDF)
	и рейтинг*/
	vector<Document> FindAllDocuments(const Query& query) const {
		map<int, double> document_to_relevance;
		/*Проходимся по плюс-словам поискового запроса*/
		for (const string& word : query.plus_words) {
			/*Если плюс-слово отсутствует в документах переходим на новую иттерацию*/
			if (word_to_document_freqs_.count(word) == 0) {
				continue;
			}
			/*Если плюс-слово присутствует в документах вычисляем его IDF с помощью заготовленной функции
			и сохраняем в переменную*/
			const double i_d_f = IDF(word);
			/*Вычисляем общую релевантность рейтинг слова умножив его TF и IDF и сохраняем её значение в document_relevance*/
			for (const auto& [document_id, TF] : word_to_document_freqs_.at(word)) {
				document_to_relevance[document_id] += TF * i_d_f;
			}
		}

		/* Проверяем в собрании документов наличие минус-слов указанных в строке запроса */
		for (const string& word : query.minus_words) {
			if (word_to_document_freqs_.count(word) == 0) {
				continue;
			}
			/*Если минус-слово найлено очищаем от него document_to_relevance*/
			for (const auto [document_id, _] : word_to_document_freqs_.at(word)) {
				document_to_relevance.erase(document_id);
			}
		}


		/*Объявляем вектор триад и переносим в него данные из контейнера map document_to_relevance*/
		vector<Document> matched_documents;

		for (const auto [document_id, relevance] : document_to_relevance) {
			for (const auto [id, rating] : document_ratings_) {
				if (id == document_id) {
					matched_documents.push_back({ document_id, relevance, rating });
				}
				else {
					continue;
				}
			}
		}

		return matched_documents;
	}
};

/*- ПРИНИМАЕТ СТРОКУ СТОП-СЛОВ;
- ПРИНИМАЕТ КОЛ-ВО ДОКУМЕНТОВ И ВВОД САМИХ СТРОК ДОКУМЕНТОВ*/
SearchServer CreateSearchServer() {
	SearchServer search_server;
	search_server.SetStopWords(ReadLine());

	const int document_count = ReadLineWithNumber();
	for (int document_id = 0; document_id < document_count; ++document_id) {
		search_server.AddDocument(document_id, ReadLine());
		search_server.AverageRating(document_id, ReadLineNumberRatings());
	}

	return search_server;
}


int main() {
	const SearchServer search_server = CreateSearchServer();

	const string query = ReadLine();
	for (auto [document_id, relevance, rating] : search_server.FindTopDocuments(query)) {
		cout << "{ document_id = "s << document_id << ", " << "relevance = "s << relevance << ", " << " rating = "s << rating << " }"s << endl;
	}

	return 0;
}
